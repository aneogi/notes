

-------------------------------------
Question  3: Incorrect
Your team is developing a set of Lambda functions. You need to ensure the team uses the best practises for working with AWS Lambda. Which of the following is an advantage on instantiating the AWS Client outside of the AWS Lambda function handler?

Explanation
This is given as one of the best practises for AWS Lambda in the documentationTake advantage of Execution Context reuse to improve the performance of your function. Make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution. Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.Since this is clearly given in the AWS Documentation, all other options are invalidFor more information on Best practices, please refer to the below URLhttps://docs.aws.amazon.com/lambda/latest/dg/best-practices.htmlThe correct answer is: Ability to reuse Execution Context

-------------------------------------
Question  4: Incorrect
Your company has a SOAP service that receives requests in XML. The service is going to be placed behind the API gateway service. Which of the following must be done to ensure that requests made to the API gateway service can be consumed by the SOAP service?

Explanation
The AWS Documentation mentions the followingIn API Gateway, an API's method request can take a payload in a different format from the corresponding integration request payload, as required in the backend. Similarly, the backend may return an integration response payload different from the method response payload, as expected by the frontend. API Gateway lets you use mapping templates to map the payload from a method request to the corresponding integration request and from an integration response to the corresponding method response.A mapping template is a script expressed in Velocity Template Language (VTL) and applied to the payload using JSONPath expressions. The payload can have a data model according to the JSON schema draft 4. You must define the model in order to have API Gateway to generate a SDK or to enable basic request validation for your API. You do not have to define any model to create a mapping template. However, a model can help you create a template because API Gateway will generate a template blueprint based on a provided model.Option B is incorrect since this is used to customize gateway responsesOption C is incorrect since this is used specifically for binary workloadsOption D is incorrect since this is used for use within a VPCFor more information on models and mappings, please refer to the below URLhttps://docs.aws.amazon.com/apigateway/latest/developerguide/models-mappings.htmlThe correct answer is: Create a mapping template

-------------------------------------
Question  6: Incorrect
Your company has a development application that needs to interact with an S3 bucket. There is a requirement that all data in the bucket is encrypted at rest. You also need to ensure that the keys are managed by you. Which of the following can you use for this purpose? Choose 2 answers from the options given below

Explanation
This is given in the AWS DocumentationUse Server-Side Encryption with Customer-Provided Keys (SSE-C) – You manage the encryption keys and Amazon S3 manages the encryption, as it writes to disks, and decryption, when you access your objects.You can encrypt data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and related toolsOptions A and B are incorrect since here the keys are managed by AWS.For more information on Server-side encryption for S3, please refer to the below URLhttps://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.htmlThe correct answers are: Server-Side Encryption with Customer-Provided Keys, Client-Side Encryption

-------------------------------------
Question  17: Incorrect
As a developer, you are writing an application that will be hosted on an EC2 Instance. This application will interact with a queue defined using the Simple Queue service. The messages will appear in the queue during a 20-60 second time duration. Which of the following strategy should be used to effectively query the queue for messages?

Explanation
This is mentioned in the AWS DocumentationLong polling offers the following benefits:· Eliminate empty responses by allowing Amazon SQS to wait until a message is available in a queue before sending a response. Unless the connection times out, the response to the ReceiveMessage request contains at least one of the available messages, up to the maximum number of messages specified in the ReceiveMessage action.· Eliminate false empty responses by querying all—rather than a subset of—Amazon SQS servers.Option A is invalid since this is used for storing undelivered messagesOption B is invalid since this is used for First In First Out queuesOption D is invalid since this is used when messages are immediately available in the queueFor more information on long polling, please visit the following URLhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.htmlThe correct answer is: Use long polling

-------------------------------------
Question  24: Incorrect
Your team is looking towards deploying an application into Elastic beanstalk. They want to deploy different versions of the application onto the environment. How can they achieve this in the easiest possible way?

Explanation
The AWS Documentation mentions the followingElastic Beanstalk creates an application version whenever you upload source code. This usually occurs when you create an environment or upload and deploy code using the environment management console or EB CLI. Elastic Beanstalk deletes these application versions according to the application's lifecycle policy and when you delete the application.Options A and B are incorrect since this would be the least efficient ways to maintain application revisionsOption D is incorrect since you would not use CodePipeline for application versionsFor more information on application versions, please refer to the below URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-versions.htmlThe correct answer is: Upload the application versions to the environment

-------------------------------------
Question  35: Incorrect
Your developing an application that is going to make use of AWS Cognito. The default sign-in and sign-up features of the AWS Cognito service will be used. There is a security requirement to ensure that if the user’s credentials are compromised, then they would need to use a new password. Which of the following needs to be in place for this? Choose 2 answers from the options given below

Explanation
This is given in the AWS DocumentationOption C is incorrect since this configuration needs to be done in the Advanced Security sectionOption D is incorrect since this is used to create unique identities for your users and federate them with identity providers and there is no mention of this in the requirementFor more information on Cognito User pools, please refer to the below URLhttps://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-compromised-credentials.htmlThe correct answers are: Ensure to create a user pool in AWS Cognito, Ensure to “Block use” for compromised credentials in the Advanced Security section

-------------------------------------
Question  37: Incorrect
You are a developer for a company that is planning on using the AWS RDS service. Your Database administrator spins up a new MySQL RDS Instance in AWS. You now need to connect to that instance. How can you achieve this? Choose 2 answers from the options given below.

Explanation
The AWS Documentation mentions the followingBefore you can connect to a DB instance running the MySQL database engine, you must create a DB instance. For information, seeCreating a DB Instance Running the MySQL Database Engine. Once Amazon RDS provisions your DB instance, you can use any standard MySQL client application or utility to connect to the instance. In the connection string, you specify the DNS address from the DB instance endpoint as the host parameter and specify the port number from the DB instance endpoint as the port parameter.You can use the AWS Management Console, the AWS CLI describe-db-instances command, or the Amazon RDS API DescribeDBInstances action to list the details of an Amazon RDS DB instance, including its endpointOptions B and D are incorrect since you need to use the endpoints to connect to the databaseFor more information on connecting to a database endpoint , please refer to the below URLhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ConnectToInstance.htmlThe correct answers are: Use the DescribeDBInstances API and get the endpoint for the database instance, Request the DBA for the endpoint for the Instance via the AWS Console

-------------------------------------
Question  39: Incorrect
Your working on a system that will make use of AWS Kinesis. Here you will various log sources that will send data onto AWS Kinesis. You are looking at creating an initial number of shards for the Kinesis stream. Which of the following can be used in the calculation for the an initial number of shards for the Kinesis stream. Choose 2 answers from the options given below.

Explanation
This is given in the AWS DocumentationFor more information on Amazon Kinesis streams, please refer to the below URLhttps://docs.aws.amazon.com/streams/latest/dev/amazon-kinesis-streams.htmlThe correct answers are: Incoming write bandwidth, Outgoing read bandwidth

-------------------------------------
Question  40: Incorrect
You are a developer for an application. The application needs to make use of AWS for managing authentication. The users should be able to authenticate using identity providers such as Facebook and Google. At the same time, you also need to enable guest user access to limited resources. How can you achieve this in the best possible way?

Explanation
The AWS Documentation mentions the followingAmazon Cognito identity pools support both authenticated and unauthenticated identities. Authenticated identities belong to users who are authenticated by any supported identity provider. Unauthenticated identities typically belong to guest users.Option A is incorrect since this would be too much of a maintenance overhead to maintain the usersOption C is incorrect since we don’t need federation access over hereOption D is incorrect since we don’t need Sync capabilities hereFor more information on Identity pools, please refer to the below URLhttps://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.htmlThe correct answer is: Use AWS Cognito and identity pools with both authenticated and unauthenticated identities

-------------------------------------
Question  43: Incorrect
Your development team is testing out an application that is being deployed onto AWS Elastic Beanstalk. The application needs to have an RDS Instance provisioned as part of the Elastic Beanstalk setup. But they want to ensure that the database is preserved for analysis even after the environment is torn down. How can you achieve this? Choose 2 answers from the options given below

Explanation
The AWS Documentation mentions that you should ensure the Retention field is marked as “Create snapshot” for ensuring the database lives even after environment is deleted.Alternatively, you can also ensure that the database is created outside of the Elastic beanstalk environmentOption B is incorrect since it is not necessary that the engine type only has to be MySQLOption D is incorrect since the option should be “Create Snapshot”For more information on managing a database in Elastic Beanstalk, please refer to the below URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.db.htmlThe correct answers are: Ensure the database is created outside of the Elastic beanstalk environment, Ensure that the retention for the database is marked as “Create Snapshot”

-------------------------------------
Question  44: Incorrect
An application is publishing a custom CloudWatch metric any time an HTTP 504 error appears in the application error logs. These errors are being received intermittently. There is a CloudWatch Alarm for this metric and the Developer would like the alarm to trigger ONLY if it breaches two evaluation periods or more.What should be done to meet these requirements?

Explanation
Since the data is being received intermittently, its better to collect and aggregate the results at regular intervals and then send the data to Cloudwatch.Option A is incorrect since here there is no mention of any special kind of notificationOption B is incorrect since you don’t need to mention a 0 value , just place a 1 value when the result is received.Option C is incorrect since there is no mention on the frequency , so we don’t know if we need high resolution for metricsFor more information on aggregation of data in Cloudwatch please refer to the below linkhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-common-scenarios.html#CloudWatch-Agent-aggregating-metricsThe correct answer is: Aggregate the data before pushing to CloudWatch by using statistic sets. 

-------------------------------------
Question  52: Incorrect
You are a developer for a company. You have to develop an application which would transfer the logs from several EC2 Instances to an S3 bucket. Which of the following would you use for this purpose?

Explanation
This is mentioned in the AWS DocumentationAWS Data Pipeline is a web service that you can use to automate the movement and transformation of data. With AWS Data Pipeline, you can define data-driven workflows, so that tasks can be dependent on the successful completion of previous tasks. You define the parameters of your data transformations and AWS Data Pipeline enforces the logic that you've set up.Option A is incorrect since this is used specifically for migrating databasesOption B is incorrect since this is used for performing SQL queries in data stored on S3Option D is incorrect since this is used for Big data applicationsFor more information on AWS Pipeline, please visit the following URLhttps://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/what-is-datapipeline.htmlThe correct answer is: AWS Data Pipeline

-------------------------------------
Question  60: Incorrect
Your team is using the AWS CodeBuild service for an application build. As part of Integration testing during the build phase, the application needs to access an RDS instance in a private subnet. How can you ensure this is possible?

Explanation
This is given in the AWS DocumentationTypically, resources in an VPC are not accessible by AWS CodeBuild. To enable access, you must provide additional VPC-specific configuration information as part of your AWS CodeBuild project configuration. This includes the VPC ID, the VPC subnet IDs, and the VPC security group IDs. VPC-enabled builds are then able to access resources inside your VPC. VPC connectivity from AWS CodeBuild builds makes it possible to:Run integration tests from your build against data in an Amazon RDS database that's isolated on a private subnet.Query data in an Amazon ElastiCache cluster directly from tests.Interact with internal web services hosted on Amazon EC2, Amazon ECS, or services that use internal Elastic Load Balancing.Since the requirements are clearly mentioned in the documentation , all other options are incorrectFor more information on VPC support for AWS CodeBuild, please refer to the below URLhttps://docs.aws.amazon.com/codebuild/latest/userguide/vpc-support.htmlThe correct answer is: Provide additional VPC-specific configuration information as part of your AWS CodeBuild project

-------------------------------------
Question  69: Incorrect
Your team has developed a web application that will run on an EC2 Instance. There is a deployment requirement wherein if the primary application fails, the requests need to be routed to a static web site. Which of the following can help you achieve this?

Explanation
The AWS Documentation mentions the followingAmazon Route 53 health checks monitor the health and performance of your web applications, web servers, and other resources. Each health check that you create can monitor one of the following:· The health of a specified resource, such as a web server· The status of other health checks· The status of an Amazon CloudWatch alarmOptions A and B are incorrect since the Load balancers are used to distribute traffic and not divert trafficOption D is incorrect since the application is not being hosted on Elastic BeanstalkFor more information on DNS failover, please refer to the below URLhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.htmlThe correct answer is: A health check in Route 53

-------------------------------------
Question  75: Incorrect
As a developer you are looking at making use of AWS Cognito Sync. Which of the below are features of this service. Choose 2 answers from the options given below.

Explanation
The AWS Documentation mentions the followingAmazon Cognito Sync is an AWS service and client library that enable cross-device syncing of application-related user data. You can use it to synchronize user profile data across mobile devices and web applications. The client libraries cache data locally so your app can read and write data regardless of device connectivity status. When the device is online, you can synchronize data, and if you set up push sync, notify other devices immediately that an update is available.Since the documentation clearly gives the features of this service, all other options are invalidFor more information on AWS Cognito Sync, please refer to the below URLhttps://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-sync.htmlThe correct answers are: Cross-device syncing of application-related user data, Push Sync Notification

-------------------------------------
Question  83: Incorrect
Your team has configured an environment in Elastic beanstalk using the following configurationJava 7 with tomcat 7They now want to change the configuration to Java 8 with Tomcat 8.5. How can they achieve this in the easiest way possible?

Explanation
This is mentioned in the AWS DocumentationSince the documentation clearly mentions the way configuration changes are made, all other options are invalidFor more information on using Elastic beanstalk configuration changes, please visit the following URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.platform.upgrade.htmlThe correct answer is: Create a new environment and port the application

-------------------------------------
Question  84: Incorrect
Your team is developing a set of Lambda functions. They need to debug the Lambda functions using the X-Ray service. Which of the following are environment variables which are used by AWS Lambda to communicate with the X-Ray service? Choose 3 answers from the options given below

Explanation
The AWS Documentation mentions the followingAWS Lambda uses environment variables to facilitate communication with the X-Ray daemon and configure the X-Ray SDK.· _X_AMZN_TRACE_ID: Contains the tracing header, which includes the sampling decision, trace ID, and parent segment ID. If Lambda receives a tracing header when your function is invoked, that header will be used to populate the _X_AMZN_TRACE_ID environment variable. If a tracing header was not received, Lambda will generate one for you.· AWS_XRAY_CONTEXT_MISSING: The X-Ray SDK uses this variable to determine its behavior in the event that your function tries to record X-Ray data, but a tracing header is not available. Lambda sets this value to LOG_ERROR by default.· AWS_XRAY_DAEMON_ADDRESS: This environment variable exposes the X-Ray daemon's address in the following format: IP_ADDRESS:PORT. You can use the X-Ray daemon's address to send trace data to the X-Ray daemon directly, without using the X-Ray SDK.For more information on using Lambda with X-Ray, please refer to the below URLhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.htmlThe correct answers are: _X_AMZN_TRACE_ID, AWS_XRAY_CONTEXT_MISSING, AWS_XRAY_DAEMON_ADDRESS

-------------------------------------
Question  86: Incorrect
Your team is working on an API definition which will be deployed using the API gateway service. You then need to ensure that control is established on who can access the various resources within the API gateway. Which of the following can help ensure this security requirement is met?

Explanation
This is given in the AWS DocumentationSince this is clearly given in the documentation, all other options are incorrectFor more information on using IAM Policies for controlling access, please refer to the below URLhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-control-access-using-iam-policies-to-invoke-api.htmlThe correct answer is: IAM Policies

-------------------------------------
Question  88: Incorrect
You’ve just deployed an AWS Lambda function. This Lambda function would be invoked via the API gateway service. You want to know if there were any errors while the Lambda function was being invoked. Which of the following service would allow you to check the performance of your underlying Lambda function.

Explanation
In AWS Lambda , you can use Cloudwatch metrics to see the number of Invocation errors. The below snapshot from the AWS Documentation shows an example on this.Option A is invalid because this service is used to get the network traffic entering your VPCOption C is invalid because this service is used to monitor API ActivityOption D is invalid because this service does not have the ability to give you the metrics for the Lambda service.For more information on accessing metrics for AWS Lambda, please refer to the below linkhttps://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-access-metrics.htmlThe correct answer is: Cloudwatch

-------------------------------------
Question  93: Incorrect
Your team is planning on delivering content to users by using the Cloudfront service and an S3 bucket as the source. You need to ensure that a custom value is placed for the amount of time the object is stored in the Cloudfront cache. Which of the following 2 options can be used to fulfil this requirement?

Explanation
This is also mentioned in the AWS DocumentationFor web distributions, to control how long your objects stay in a CloudFront cache before CloudFront forwards another request to your origin, you can:· Configure your origin to add a Cache-Control or an Expires header field to each object.· Specify a value for Minimum TTL in CloudFront cache behaviors.· Use the default value of 24 hours.Since this is clearly mentioned in the AWS Documentation , the other options are invalidFor more information on request and response behaviour for Cloudfront with S3, please refer to the below URLhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorS3Origin.htmlThe correct answers are: Configure the origin to add an Expires header field to the object , Specify a value for Minimum TTL in CloudFront cache behaviors

-------------------------------------
Question  94: Incorrect
You’re in charge for creating a cloudformation template. This template needs to create resources for multiple types of environment. The template needs to be flexible so that it can create resources based on the type of environment. How can you achieve this? Choose 2 answers from the options given below.

Explanation
This is given in the AWS DocumentationThe optional Conditions section contains statements that define the circumstances under which entities are created or configured. For example, you can create a condition and then associate it with a resource or output so that AWS CloudFormation only creates the resource or output if the condition is true. Similarly, you can associate the condition with a property so that AWS CloudFormation only sets the property to a specific value if the condition is true. If the condition is false, AWS CloudFormation sets the property to a different value that you specify.You might use conditions when you want to reuse a template that can create resources in different contexts, such as a test environment versus a production environment. In your template, you can add an EnvironmentType input parameter, which accepts either prod or test as inputs.Since this is clearly given in the documentation, all other options are incorrectFor more information on conditions in a Cloudformation template, please refer to the below URLhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.htmlThe correct answers are: Create an Input Parameter to take in the type of environment., Use the Conditions section to create resources based on the type of environment

-------------------------------------
Question  98: Incorrect
You have developed a Lambda function. This function needs to run on a scheduled basis. Which of the following can be done to accomplish this requirement in an ideal manner?

Explanation
The AWS Documentation mentions the followingOption A is incorrect since there is no inbuilt scheduler in AWS LambdaOption B is incorrect since this would add more maintenance overheadOption D is incorrect since this service is an API monitoring serviceFor more information on running Lambda functions on schedules, please refer to the below URLhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.htmlThe correct answer is: Use Cloudwatch events to schedule the Lambda function

-------------------------------------
Question  103: Incorrect
Your team is planning on deploying an application using the worker environment on AWS Elastic beanstalk. Which of the following is an additional requirement for a worker environment in AWS Elastic Beanstalk?

Explanation
The AWS Documentation mentions the followingWhen you use the AWS Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must meet the following requirements:· Consist of a single ZIP file or WAR file (you can include multiple WAR files inside your ZIP file)· Not exceed 512 MB· Not include a parent folder or top-level directory (subdirectories are fine)If you want to deploy a worker application that processes periodic background tasks, your application source bundle must also include a cron.yaml fileSince this is clearly mentioned in the documentation all other options are incorrect.For more information on application source bundles in Elastic beanstalk, please refer to the below URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.htmlThe correct answer is: Ensure that the application contains a file called cron.yaml

-------------------------------------
Question  105: Incorrect
You’ve developed an application that is going to be hosted on an EC2 Instance. The company has decided to use Cloudfront to distribute the content. The IT Security department has mandated that the traffic is encrypted between Cloudfront and the Viewer and Cloudfront and the origin as well. How can you achieve this? Choose 2 answers from the options given below.

Explanation
This is given in the AWS DocumentationSince this is clearly given in the documentation, all other options are incorrectFor more information on configuring HTTPS between the Viewer and Cloudfront and the Origin and Cloudfront, please refer to the below URLhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.htmlhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.htmlThe correct answers are: Ensure that the Viewer Protocol policy is set to HTTPS only or Redirect HTTP to HTTPS, Ensure that the Origin Protocol policy is set to HTTPS only

-------------------------------------
Question  106: Incorrect
You are currently working on a function for AWS Lambda. When uploading the package for your AWS Lambda function, you are receiving the following errorCodeStorageExceededException What can you do to surpass this error?

Explanation
The AWS Documentation mentions the followingSince the documentation clearly mentions this , all other options are invalid.For more information on limits for AWS Lambda, please refer to the below URLhttps://docs.aws.amazon.com/lambda/latest/dg/limits.htmlThe correct answer is: Reduce the size for your code

-------------------------------------
Question  110: Incorrect
Your team is working on an application that it going to work with a DynamoDB table. At the design stage, you are trying to find out the optimum way to define partition keys and secondary indexes. Which of the following are recommendations for defining secondary indexes? Choose 2 answers from the options given below.

Explanation
The AWS Documentation mentions the following· Keep the number of indexes to a minimum. Don't create secondary indexes on attributes that you don't query often. Indexes that are seldom used contribute to increased storage and I/O costs without improving application performance.· Avoid indexing tables that experience heavy write activity. In a data capture application, for example, the cost of I/O operations required to maintain an index on a table with a very high write load can be significant. If you need to index data in such a table, it may be more effective to copy the data to another table that has the necessary indexes and query it there.Since the documentation mentions this clearly, all other options are invalidFor more information on working with indexes, please refer to the below URLhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.htmlThe correct answers are: Keep the number of indexes to a minimum, Avoid indexing tables that experience heavy write activity

-------------------------------------
Question  111: Incorrect
You’ve setup an application on a set of EC2 Instances. It is a web-based application. You’ve also setup a load balancer. During the initial round of testing after deploying, the users complain that they are not able to reach the home page for the web based application. Which of the following must you check? Choose 2 answers from the options given below

Explanation
This is given in the AWS DocumentationOption A is invalid since the load balancer should be attached to a public subnetOption D is invalid since the Security Group for the Load balancer should allow traffic from the internetFor more information on troubleshooting the load balancer, please refer to the below URLhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-troubleshooting.htmlThe correct answers are: Ensure that the load balancer is attached to a public subnet, Ensure that the Security Group of the Load balancer allows traffic from the internet

-------------------------------------
Question  112: Incorrect
A developer is writing an application that will store data in a DynamoDB table. The ratio of reads operations to write operations will be 1000 to 1, with the same data being accessed frequently.What should the Developer enable on the DynamoDB table to optimize performance and minimize costs?

Explanation
The AWS Documentation mentions the followingDAX is a DynamoDB-compatible caching service that enables you to benefit from fast in-memory performance for demanding applications. DAX addresses three core scenarios:1.       As an in-memory cache, DAX reduces the response times of eventually-consistent read workloads by an order of magnitude, from single-digit milliseconds to microseconds.2.       DAX reduces operational and application complexity by providing a managed service that is API-compatible with Amazon DynamoDB, and thus requires only minimal functional changes to use with an existing application.3.       For read-heavy or bursty workloads, DAX provides increased throughput and potential operational cost savings by reducing the need to over-provision read capacity units. This is especially beneficial for applications that require repeated reads for individual keys.Option A is incorrect since this is good when you have unpredictable workloadsOption B is incorrect since this is good for disaster recovery scenariosOption C is incorrect since this is good to stream data to other sourcesFor more information on DynamoDB Accelerator, please refer to the below linkhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.htmlThe correct answer is: Amazon DynamoDB Accelerator


#####################################################################################################################

Attempt 2

-------------------------------------
Question  3: Incorrect
You are configuring Cross Origin for your S3 bucket. You need to ensure that external domain sites can only issue the GET requests against your bucket. Which of the following would you modify as part of the CORS configuration for this requirement?

Explanation
This is mentioned in the AWS DocumentationOption A is invalid since this is used to specify the origins that you want to allow cross-domain requestsOption B is invalid since this is used to specify which headers are allowed in a preflight request through the Access-Control-Request-Headers headerOption D is invalid since this is used to specify the time in seconds that your browser can cache the response for a preflight request as identified by the resource, the HTTP method, and the originFor more information on CORS, please refer to the below URLhttps://docs.aws.amazon.com/AmazonS3/latest/dev/cors.htmlThe correct answer is: AllowedMethod Element

-------------------------------------
Question  5: Incorrect
Your team is looking towards deploying an application into Elastic beanstalk. They want to deploy different versions of the application onto the environment. How can they achieve this in the easiest possible way?

Explanation
The AWS Documentation mentions the followingElastic Beanstalk creates an application version whenever you upload source code. This usually occurs when you create an environment or upload and deploy code using the environment management console or EB CLI. Elastic Beanstalk deletes these application versions according to the application's lifecycle policy and when you delete the application.Options A and B are incorrect since this would be the least efficient ways to maintain application revisionsOption D is incorrect since you would not use CodePipeline for application versionsFor more information on application versions, please refer to the below URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-versions.htmlThe correct answer is: Upload the application versions to the environment

-------------------------------------
Question  16: Incorrect
You are currently developing an application that consists of a web layer hosted on an EC2 Instance. This is interacting with the database layer using the AWS RDS Instance. You are noticing that the same query reads are causing performance issues for the application. Which of the following can be used to alleviate this issue?

Explanation
This is mentioned in the AWS DocumentationAmazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, run, and scale popular open source compatible in-memory data stores. Build data-intensive apps or improve the performance of your existing apps by retrieving data from high throughput and low latency in-memory data stores. Amazon ElastiCache is a popular choice for Gaming, Ad-Tech, Financial Services, Healthcare, and IoT apps.Options A and B are incorrect since the ELB will not resolve the issue. It can only direct the traffic and not reduce the latency issues.Option D is incorrect since this should ideally be placed in front of a data storeFor more information on ElastiCache, please visit the following URLhttps://aws.amazon.com/elasticache/The correct answer is: Place an Elastic Cache in front of the database layer

-------------------------------------
Question  20: Incorrect
You have an application that is currently being deployed using the AWS CodeDeploy tool. Now as per Security procedures , you don’t have access to the CodeDeploy project in the console, although you do have access to run the build. You want to specify a different source location for the build. How can you achieve this?

Explanation
Options A and B are incorrect since the 
-------------------------------------
Question  mentions that you don’t have access to the projectOption D is incorrect since you have to use the start-build commandThe AWS Documentation mentions the followingTo override the default build spec file name, location, or both, do one of the following:·         Run the AWS CLI create-project or update-project command, setting the buildspec value to the path to the alternate build spec file relative to the value of the built-in environment variable CODEBUILD_SRC_DIR. You can also do the equivalent with the create project operation in the AWS SDKs. For more information, see Create a Build Project or Change a Build Project's Settings.·         Run the AWS CLI start-build command, setting the buildspecOverride value to the path to the alternate build spec file relative to the value of the built-in environment variable CODEBUILD_SRC_DIR. You can also do the equivalent with the start build operation in the AWS SDKsFor more information on the build specification for AWS Code Deploy, please refer to the below linkhttps://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.htmlThe correct answer is: Specify the new location of the build in the buildspec.yml file and use the start-build command

-------------------------------------
Question  26: Incorrect
Your team is working on an API definition which will be deployed using the API gateway service. You then need to ensure that control is established on who can access the various resources within the API gateway. Which of the following can help ensure this security requirement is met?

Explanation
This is given in the AWS DocumentationSince this is clearly given in the documentation, all other options are incorrectFor more information on using IAM Policies for controlling access, please refer to the below URLhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-control-access-using-iam-policies-to-invoke-api.htmlThe correct answer is: IAM Policies

-------------------------------------
Question  30: Incorrect
As a developer you are looking at making use of AWS Cognito Sync. Which of the below are features of this service. Choose 2 answers from the options given below.

Explanation
The AWS Documentation mentions the followingAmazon Cognito Sync is an AWS service and client library that enable cross-device syncing of application-related user data. You can use it to synchronize user profile data across mobile devices and web applications. The client libraries cache data locally so your app can read and write data regardless of device connectivity status. When the device is online, you can synchronize data, and if you set up push sync, notify other devices immediately that an update is available.Since the documentation clearly gives the features of this service, all other options are invalidFor more information on AWS Cognito Sync, please refer to the below URLhttps://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-sync.htmlThe correct answers are: Cross-device syncing of application-related user data, Push Sync Notification

-------------------------------------
Question  45: Incorrect
Your company currently has an S3 bucket hosted in an AWS Account. It holds information that needs be accessed by a partner account. Which is the MOST secure way to allow the partner account to access the S3 bucket in your account. Choose 3 answers from the options given below.

Explanation
The AWS documentation showcases an example on this wherein an IAM role and external ID is used to access an AWS account resourcesOption B is invalid because Roles are assumed and not IAM usersOption E is invalid because you should not give the account ID to the partnerOption F is invalid because you should not give the access keys to the partnerFor more information on creating roles for external ID’s please visit the following URLhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.htmlThe correct answers are: Ensure an IAM role is created which can be assumed by the partner account., Ensure the partner uses an external id when making the request, Provide the ARN for the role to the partner account

-------------------------------------
Question  56: Incorrect
You have developed a Lambda function. This function needs to run on a scheduled basis. Which of the following can be done to accomplish this requirement in an ideal manner?

Explanation
The AWS Documentation mentions the followingOption A is incorrect since there is no inbuilt scheduler in AWS LambdaOption B is incorrect since this would add more maintenance overheadOption D is incorrect since this service is an API monitoring serviceFor more information on running Lambda functions on schedules, please refer to the below URLhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.htmlThe correct answer is: Use Cloudwatch events to schedule the Lambda function

-------------------------------------
Question  62: Incorrect
As a developer, you need your operations team to monitor a set of metrics for an application. They also need to be notified in case any of the metrics crosses the threshold. How can you achieve this?

Explanation
The AWS Documentation mentions the followingYou can create a CloudWatch alarm that watches a single metric. The alarm performs one or more actions based on the value of the metric relative to a threshold over a number of time periods. The action can be an Amazon EC2 action, an Amazon EC2 Auto Scaling action, or a notification sent to an Amazon SNS topic. You can also add alarms to CloudWatch dashboards and monitor them visually. When an alarm is on a dashboard, it turns red when it is in the ALARM state, making it easier for you to monitor its status proactively.You can publish your own metrics to CloudWatch using the AWS CLI or an API. You can view statistical graphs of your published metrics with the AWS Management Console.Option B is invalid since this is used for logging purposes and here you need to view the metricsOption C is invalid since this is used for API monitoring purposesOption D is invalid since here we have to assume that we need to monitor metrics for an application and hence you would need to publish custom metricsFor more information on publishing custom metrics and alarms, please refer to the below URLhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.htmlhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.htmlThe correct answer is: Publish custom metrics for the application that can be monitored via Cloudwatch. Create Alarms for notifications.

-------------------------------------
Question  64: Incorrect
Your development team is planning on building an application based on the Microservice architecture pattern. Docker containers would be used to build the application. When deploying the application to AWS, which of the following services should be considered. Choose 2 answers from the options given below?

Explanation
The AWS Documentation, shows the example of a simple Microservices ArchitectureOption A is incorrect since ECS should be preferred for its ability to provide a serverless architecture for your docker containersOption D is incorrect since the Application Load balancer has better support for docker containers.For more information on a simple microservices architecture, please refer to the below URLhttps://docs.aws.amazon.com/aws-technical-content/latest/microservices-on-aws/simple-microservices-architecture-on-aws.htmlThe correct answers are: AWS ECS, Application Load balancer

-------------------------------------
Question  72: Incorrect
Your team is planning on creating a DynamoDB table and using it with their application. The team is planning on placing the initial Read capacity of 10 with the default level of consistency. The expected number of reads per second would be 2KB. What would be the throughput for reads for the underlying table?

Explanation
One read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. The default is eventually consistent read. As per the 
-------------------------------------
Question  for each 2 KB we need 1 RCU. (2/4=1 RCU - rounded to the larger whole number)So for 10 RCU we can have up to 20KB per sec.For more information on Throughputs, please refer to the below URLhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.htmlThe correct answer is: 20

-------------------------------------
Question  75: Incorrect
Your developing an application that is going to make use of AWS Cognito. The default sign-in and sign-up features of the AWS Cognito service will be used. There is a security requirement to ensure that if the user’s credentials are compromised, then they would need to use a new password. Which of the following needs to be in place for this? Choose 2 answers from the options given below

Explanation
This is given in the AWS DocumentationOption C is incorrect since this configuration needs to be done in the Advanced Security sectionOption D is incorrect since this is used to create unique identities for your users and federate them with identity providers and there is no mention of this in the requirementFor more information on Cognito User pools, please refer to the below URLhttps://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-compromised-credentials.htmlThe correct answers are: Ensure to create a user pool in AWS Cognito, Ensure to “Block use” for compromised credentials in the Advanced Security section

-------------------------------------
Question  77: Incorrect
Your team has configured an environment in Elastic beanstalk using the following configurationJava 7 with tomcat 7They now want to change the configuration to Java 8 with Tomcat 8.5. How can they achieve this in the easiest way possible?

Explanation
This is mentioned in the AWS DocumentationSince the documentation clearly mentions the way configuration changes are made, all other options are invalidFor more information on using Elastic beanstalk configuration changes, please visit the following URLhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.platform.upgrade.htmlThe correct answer is: Create a new environment and port the application

-------------------------------------
Question  83: Incorrect
Your team is developing a series of Lambda functions. You need to ensure that you analyse the invocations of the functions during the testing phase. Which of the following tools can help you achieve this? Choose 2 answers from the options given below.

Explanation
The AWS Documentation mentions the followingOption B is incorrect since this is used to check EC2 Instances for vulnerabilitiesOption D is incorrect since this is used to monitor API activityFor more information on troubleshooting AWS Lambda, please refer to the below URLhttps://docs.aws.amazon.com/lambda/latest/dg/troubleshooting.htmlThe correct answers are: Amazon Cloudwatch, Amazon X-Ray

-------------------------------------
Question  93: Incorrect
Your team is developing an API and wants to host using the AWS API gateway service. They don’t want to allow anonymous access and want to have an authentication mechanism in place. Which of the following can be used for authentication purposes for the API gateway? Choose 3 answers from the options given below

Explanation
The AWS Documentation mentions the followingAPI Gateway supports multiple mechanisms for controlling access to your API:· Resource policies let you create resource-based policies to allow or deny access to your APIs and methods from specified source IP addresses or VPC endpoints.· Standard AWS IAM roles and policies offer flexible and robust access controls that can be applied to an entire API or individual methods.· Cross-origin resource sharing (CORS) lets you control how your API responds to cross-domain resource requests.· Lambda authorizers are Lambda functions that control access to your API methods using bearer token authentication as well as information described by headers, paths, query strings, stage variables, or context variables request parameters.· Amazon Cognito user pools let you create customizable authentication and authorization solutions.· Client-side SSL certificates can be used to verify that HTTP requests to your backend system are from API Gateway.· Usage plans let you provide API keys to your customers — and then track and limit usage of your API stages and methods for each API key.For more information on controlling access to the API, please refer to the below URLhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-to-api.htmlThe correct answers are: Lambda authorizers, AWS Cognito, API keys

-------------------------------------
Question  99: Incorrect
Your team has just started using the API gateway service. Several AWS Lambda functions are used as the backend for the gateway service. You have deployed the API and made is available for test users. You have now made a change to the method response for the API gateway. What should you do next?

Explanation
The AWS Documentation mentions the followingTo deploy an API, you create an API deployment and associate it with a stage. Each stage is a snapshot of the API and is made available for the client to call. Every time you update an API, which includes modification of methods, integrations, authorizers, and anything else other than stage settings, you must redeploy the API to an existing stage or to a new stage.All other options are incorrect since the right way is to Redeploy the APIFor more information on how to deploy an API, please refer to the below URLhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-deploy-api.htmlThe correct answer is: Redeploy the API

-------------------------------------
Question  102: Incorrect
As a database developer, you have started working with Redshift. Your IT administrator has provisioned a Redshift cluster. You now need to load data into the Redshift cluster from S3. Which of the following command should you use for this activity?

Explanation
This is given in the AWS DocumentationThe ideal command to be used is given in the documentation , hence all other options are incorrectFor more information on working with a sample Redshift cluster, please refer to the below URLhttps://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-create-sample-db.htmlThe correct answer is: COPY

-------------------------------------
Question  107: Incorrect
Your team is planning on using the AWS Code Build service to test out the build of the application. The application needs to connect to a database. How should you store the database password in a secure manner so that it is available during the build process?

Explanation
The AWS Documentation mentions the followingWe strongly discourage using environment variables to store sensitive values, especially AWS access key IDs and secret access keys. Environment variables can be displayed in plain text using tools such as the AWS CodeBuild console and the AWS CLI.For sensitive values, we recommend you store them in the Amazon EC2 Systems Manager Parameter Store and then retrieve them from your build spec. All other options are invalid because they are all insecure ways to access passwords in applications from AWS CodeBuild.For more information on referencing environment variables, please refer to the below URLhttps://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-env-vars.htmlThe correct answer is: Store the password in AWS Systems Manager

-------------------------------------
Question  110: Incorrect
Your company has a development application that needs to interact with an S3 bucket. There is a requirement that all data in the bucket is encrypted at rest. You also need to ensure that the keys are managed by you. Which of the following can you use for this purpose? Choose 2 answers from the options given below

Explanation
This is given in the AWS DocumentationUse Server-Side Encryption with Customer-Provided Keys (SSE-C) – You manage the encryption keys and Amazon S3 manages the encryption, as it writes to disks, and decryption, when you access your objects.You can encrypt data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and related toolsOptions A and B are incorrect since here the keys are managed by AWS.For more information on Server-side encryption for S3, please refer to the below URLhttps://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.htmlThe correct answers are: Server-Side Encryption with Customer-Provided Keys, Client-Side Encryption

-------------------------------------
Question  113: Incorrect
You are using a custom tool known as POSTMAN to make API requests to resources in AWS. Part of the job of sending requests is to sign the request. Which of the following would you use to sign the API requests made to AWS?

Explanation
The AWS Documentation mentions the followingWhen you send HTTP requests to AWS, you sign the requests so that AWS can identify who sent them. You sign requests with your AWS access key, which consists of an access key ID and secret access key. Some requests do not need to be signed, such as anonymous requests to Amazon Simple Storage Service (Amazon S3) and some API operations in AWS Security Token Service (AWS STS) such as AssumeRoleWithWebIdentity.Option A is incorrect since this is used for console-based accessOption B is incorrect since this is used for logging onto EC2 InstancesOption C is incorrect since this is use for encrypting dataFor more information on signing API requests, please refer to the below URLhttps://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.htmlThe correct answer is: Access Keys

